{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pDgJO7cWqS4"
      },
      "source": [
        "# Setup\n",
        "- run `zip_for_colab.py` locally in the NLP-project directory\n",
        "- upload the resulting zip file `nlp_proj_colab.zip`\n",
        "- upload your data CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kn8ThZwOWjU0",
        "outputId": "54566718-f850-4677-8cef-efb10a75b8e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/nlp_proj_colab.zip\n",
            "   creating: configs/\n",
            "   creating: environment/\n",
            "   creating: src/\n",
            "  inflating: pyproject.toml          \n",
            "  inflating: setup.cfg               \n",
            "   creating: configs/multitask/\n",
            "   creating: configs/singletask/\n",
            "  inflating: configs/singletask/bert_classifier_hv.yml  \n",
            "  inflating: configs/singletask/bilstm_regressor_svo_dist.yml  \n",
            "  inflating: configs/singletask/bert_classifier_scv.yml  \n",
            "  inflating: configs/singletask/bert_regressor_svo_dist_norm.yml  \n",
            "  inflating: configs/singletask/bilstm_classifier_svo_dist_norm_disc10.yml  \n",
            "  inflating: configs/singletask/bilstm_classifier_scv.yml  \n",
            "  inflating: configs/singletask/bilstm_classifier_hv.yml  \n",
            "  inflating: configs/singletask/bert_classifier_freeze_apv.yml  \n",
            "  inflating: configs/singletask/bert_regressor_svo_dist.yml  \n",
            "  inflating: configs/singletask/bilstm_classifier_apv.yml  \n",
            "  inflating: configs/singletask/bilstm_regressor_svo_dist_norm.yml  \n",
            "  inflating: configs/singletask/bilstm_classifier_svo_dist_norm_disc5.yml  \n",
            "  inflating: configs/singletask/bilstm_classifier_svo_dist_norm_disc20.yml  \n",
            "  inflating: configs/singletask/bert_classifier_apv.yml  \n",
            "  inflating: configs/multitask/bilstm_multitask_2.yml  \n",
            "  inflating: configs/multitask/bilstm_multitask.yml  \n",
            "  inflating: configs/multitask/bilstm_multitask_3.yml  \n",
            "  inflating: environment/requirements.txt  \n",
            "  inflating: environment/environment.yml  \n",
            "  inflating: environment/install.sh  \n",
            "  inflating: environment/requirements-colab-train.txt  \n",
            "   creating: src/nlp_proj/\n",
            "   creating: src/nlp_proj.egg-info/\n",
            "   creating: src/nlp_proj/__pycache__/\n",
            "  inflating: src/nlp_proj/model_active_voice.py  \n",
            "  inflating: src/nlp_proj/stanza_annotate_active_voice.py  \n",
            "  inflating: src/nlp_proj/train_utils_multitask.py  \n",
            "  inflating: src/nlp_proj/model_bilstm_baseline.py  \n",
            "  inflating: src/nlp_proj/model_bert_singletask.py  \n",
            "  inflating: src/nlp_proj/data_loader.py  \n",
            "  inflating: src/nlp_proj/__init__.py  \n",
            "  inflating: src/nlp_proj/dataset_utils.py  \n",
            "  inflating: src/nlp_proj/metric_utils.py  \n",
            "  inflating: src/nlp_proj/train_utils_singletask.py  \n",
            "  inflating: src/nlp_proj/train.py   \n",
            "  inflating: src/nlp_proj/stanza_annotate.py  \n",
            "  inflating: src/nlp_proj/model_bilstm_multitask.py  \n",
            "  inflating: src/nlp_proj/model_bert_multitask.py  \n",
            "  inflating: src/nlp_proj/manual_annotate.py  \n",
            "  inflating: src/nlp_proj/model_optim_utils.py  \n",
            "  inflating: src/nlp_proj/config_utils.py  \n",
            "  inflating: src/nlp_proj/__pycache__/model_bilstm_multitask.cpython-37.pyc  \n",
            "  inflating: src/nlp_proj/__pycache__/model_active_voice.cpython-37.pyc  \n",
            "  inflating: src/nlp_proj/__pycache__/data_loader.cpython-310.pyc  \n",
            "  inflating: src/nlp_proj/__pycache__/model_bert_singletask.cpython-37.pyc  \n",
            "  inflating: src/nlp_proj/__pycache__/config_utils.cpython-37.pyc  \n",
            "  inflating: src/nlp_proj/__pycache__/config.cpython-37.pyc  \n",
            "  inflating: src/nlp_proj/__pycache__/train_utils_multitask.cpython-37.pyc  \n",
            "  inflating: src/nlp_proj/__pycache__/dataset_and_utils.cpython-37.pyc  \n",
            "  inflating: src/nlp_proj/__pycache__/stanza_annotate.cpython-310.pyc  \n",
            "  inflating: src/nlp_proj/__pycache__/model_bilstm_baseline.cpython-37.pyc  \n",
            "  inflating: src/nlp_proj/__pycache__/train_utils_singletask.cpython-37.pyc  \n",
            "  inflating: src/nlp_proj/__pycache__/dataset_utils.cpython-37.pyc  \n",
            "  inflating: src/nlp_proj/__pycache__/stanza_annotate.cpython-37.pyc  \n",
            "  inflating: src/nlp_proj/__pycache__/train.cpython-37.pyc  \n",
            "  inflating: src/nlp_proj/__pycache__/model_active_voice.cpython-310.pyc  \n",
            "  inflating: src/nlp_proj/__pycache__/data_loader.cpython-37.pyc  \n",
            "  inflating: src/nlp_proj/__pycache__/metric_utils.cpython-37.pyc  \n",
            "  inflating: src/nlp_proj/__pycache__/__init__.cpython-37.pyc  \n",
            "  inflating: src/nlp_proj/__pycache__/__init__.cpython-310.pyc  \n",
            "  inflating: src/nlp_proj/__pycache__/model_optim_utils.cpython-37.pyc  \n",
            "  inflating: src/nlp_proj.egg-info/PKG-INFO  \n",
            "  inflating: src/nlp_proj.egg-info/SOURCES.txt  \n",
            "  inflating: src/nlp_proj.egg-info/top_level.txt  \n",
            "  inflating: src/nlp_proj.egg-info/dependency_links.txt  \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/nlp_proj_colab.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-jH4qbbW-46",
        "outputId": "690613ba-08c6-4662-ae12-0b8835c808b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting black\n",
            "  Downloading black-22.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 29.7 MB/s \n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 82.1 MB/s \n",
            "\u001b[?25hCollecting wandb\n",
            "  Downloading wandb-0.13.6-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 56.6 MB/s \n",
            "\u001b[?25hCollecting torchmetrics\n",
            "  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n",
            "\u001b[K     |████████████████████████████████| 512 kB 79.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from -r /content/environment/requirements-colab-train.txt (line 5)) (4.64.1)\n",
            "Collecting mypy-extensions>=0.4.3\n",
            "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.8/dist-packages (from black->-r /content/environment/requirements-colab-train.txt (line 1)) (2.5.4)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from black->-r /content/environment/requirements-colab-train.txt (line 1)) (2.0.1)\n",
            "Collecting click>=8.0.0\n",
            "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 6.1 MB/s \n",
            "\u001b[?25hCollecting pathspec>=0.9.0\n",
            "  Downloading pathspec-0.10.2-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.8/dist-packages (from black->-r /content/environment/requirements-colab-train.txt (line 1)) (4.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers->-r /content/environment/requirements-colab-train.txt (line 2)) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 78.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers->-r /content/environment/requirements-colab-train.txt (line 2)) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers->-r /content/environment/requirements-colab-train.txt (line 2)) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers->-r /content/environment/requirements-colab-train.txt (line 2)) (3.8.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers->-r /content/environment/requirements-colab-train.txt (line 2)) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers->-r /content/environment/requirements-colab-train.txt (line 2)) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 100.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers->-r /content/environment/requirements-colab-train.txt (line 2)) (3.0.9)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.8/dist-packages (from wandb->-r /content/environment/requirements-colab-train.txt (line 3)) (2.3)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from wandb->-r /content/environment/requirements-colab-train.txt (line 3)) (3.19.6)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb->-r /content/environment/requirements-colab-train.txt (line 3)) (5.4.8)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 80.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from wandb->-r /content/environment/requirements-colab-train.txt (line 3)) (57.4.0)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.11.1-py2.py3-none-any.whl (168 kB)\n",
            "\u001b[K     |████████████████████████████████| 168 kB 76.4 MB/s \n",
            "\u001b[?25hCollecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from docker-pycreds>=0.4.0->wandb->-r /content/environment/requirements-colab-train.txt (line 3)) (1.15.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.5 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers->-r /content/environment/requirements-colab-train.txt (line 2)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers->-r /content/environment/requirements-colab-train.txt (line 2)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers->-r /content/environment/requirements-colab-train.txt (line 2)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers->-r /content/environment/requirements-colab-train.txt (line 2)) (2022.9.24)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.11.0-py2.py3-none-any.whl (168 kB)\n",
            "\u001b[K     |████████████████████████████████| 168 kB 77.4 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.10.1-py2.py3-none-any.whl (166 kB)\n",
            "\u001b[K     |████████████████████████████████| 166 kB 88.3 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.10.0-py2.py3-none-any.whl (166 kB)\n",
            "\u001b[K     |████████████████████████████████| 166 kB 86.9 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.10-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 86.3 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.9-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 76.3 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.8-py2.py3-none-any.whl (158 kB)\n",
            "\u001b[K     |████████████████████████████████| 158 kB 83.9 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.7-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 98.0 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.6-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 69.8 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.5-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 74.9 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.4-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 97.2 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 98.5 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 95.7 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 77.5 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n",
            "\u001b[K     |████████████████████████████████| 156 kB 78.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics->-r /content/environment/requirements-colab-train.txt (line 4)) (1.13.0+cu116)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=1f726e581d8f5a55db77eb439373b5be5f7dd537f92e59ed09dccc1626d5ad61\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, tokenizers, shortuuid, setproctitle, sentry-sdk, pathtools, pathspec, mypy-extensions, huggingface-hub, GitPython, docker-pycreds, click, wandb, transformers, torchmetrics, black\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 7.1.2\n",
            "    Uninstalling click-7.1.2:\n",
            "      Successfully uninstalled click-7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flask 1.1.4 requires click<8.0,>=5.1, but you have click 8.1.3 which is incompatible.\u001b[0m\n",
            "Successfully installed GitPython-3.1.29 black-22.10.0 click-8.1.3 docker-pycreds-0.4.0 gitdb-4.0.10 huggingface-hub-0.11.1 mypy-extensions-0.4.3 pathspec-0.10.2 pathtools-0.1.2 sentry-sdk-1.9.0 setproctitle-1.3.2 shortuuid-1.0.11 smmap-5.0.0 tokenizers-0.13.2 torchmetrics-0.11.0 transformers-4.25.1 wandb-0.13.6\n"
          ]
        }
      ],
      "source": [
        "!pip install -r /content/environment/requirements-colab-train.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQ8gF9N7UHih"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQIvck-2Z04r",
        "outputId": "30960ca8-ee30-4c56-fab1-4441ca8b6afe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:numexpr.utils:NumExpr defaulting to 4 threads.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append('/content/')\n",
        "sys.path.append('/content/src/')\n",
        "sys.path.append('/content/src/nlp_proj/')\n",
        "\n",
        "import os\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "import wandb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import logging \n",
        "from pprint import pformat\n",
        "import pathlib\n",
        "logging.getLogger().setLevel(logging.INFO)\n",
        "\n",
        "from nlp_proj.model_optim_utils import make_model, make_optimizer, make_criterion\n",
        "from nlp_proj.config_utils import load_config\n",
        "from nlp_proj.dataset_utils import make_dataloader, make_tokenizer, make_datasets\n",
        "from nlp_proj.train_utils_singletask import train_model_singletask, test_model_singletask\n",
        "from nlp_proj.train_utils_multitask import train_model_multitask, test_model_multitask\n",
        "from nlp_proj.train import model_pipeline\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9ej7IT6UI4M"
      },
      "source": [
        "# Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6MiEMW0ySLlZ"
      },
      "outputs": [],
      "source": [
        "# CONFIGURATION\n",
        "config_filepath = \"/content/configs/multitask/bert_multitask_2.yml\"  \n",
        "data_filepath = \"/content/train_auto_annotations_UPDATED_cleaned.csv\" \n",
        "results_dir = \"/content/results/bert_multitask_2/\"\n",
        "test_run = False\n",
        "test_run_n_samples = 30\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoc5UpE0Sqbn",
        "outputId": "2e4489c8-c1da-4846-ffd4-19dd4f63b7d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Loaded config:\n",
            "INFO:root:{'architecture': 'BERTMultitask',\n",
            " 'base_lr': 0.001,\n",
            " 'batch_size': 32,\n",
            " 'data_filepath': '/content/train_auto_annotations_UPDATED_cleaned.csv',\n",
            " 'device': device(type='cuda', index=0),\n",
            " 'dim_hid': 64,\n",
            " 'early_stopping': True,\n",
            " 'early_stopping_label_col': 'scv',\n",
            " 'early_stopping_metric': 'f1',\n",
            " 'freeze_pretrained': False,\n",
            " 'grad_clip': 5,\n",
            " 'label_cols': ['apv', 'scv'],\n",
            " 'label_criterion': ['CrossEntropyLoss', 'CrossEntropyLoss'],\n",
            " 'logging_freq': 20,\n",
            " 'max_epochs': 3,\n",
            " 'multitask': True,\n",
            " 'num_classes_list': [3, 3],\n",
            " 'optimizer': 'ADAM',\n",
            " 'project_name': 'bert-multitask',\n",
            " 'random_seed': 42,\n",
            " 'results_dir': '/content/results/bert_multitask_2/',\n",
            " 'shuffle': False,\n",
            " 'start_epoch': 0,\n",
            " 'tasks': ['classification', 'classification'],\n",
            " 'test_run': False,\n",
            " 'test_run_n_samples': 10,\n",
            " 'weight_decay': 0.0001}\n"
          ]
        }
      ],
      "source": [
        "# Load config\n",
        "config = load_config(config_filepath)\n",
        "config[\"data_filepath\"] = data_filepath\n",
        "config[\"results_dir\"] = results_dir\n",
        "\n",
        "# Alter config\n",
        "config[\"batch_size\"] = batch_size\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "config[\"device\"] = device\n",
        "logging.info(\"Loaded config:\")\n",
        "logging.info(pformat(config))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89rET2ggW_za",
        "outputId": "a34ae19a-1484-4c12-9967-47be5a9b4aae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Created results directory /content/results/bert_multitask_2/\n"
          ]
        }
      ],
      "source": [
        "# Create results_dir direectory\n",
        "results_dir = config[\"results_dir\"]\n",
        "if not pathlib.Path(results_dir).is_dir():\n",
        "    pathlib.Path(results_dir).mkdir(parents=True)\n",
        "    logging.info(f\"Created results directory {results_dir}\")\n",
        "else:\n",
        "    logging.warning(f\"Results directory {results_dir} already exists, and running may overwrite files\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oJmqZWYSA2E",
        "outputId": "b69c130e-7942-4f2a-88c9-dd5fc5f4d85a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Wandb setup\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sVABTDZXFru"
      },
      "source": [
        "# Run Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3560f89e3afc421b9bc6f3c9c5f88577",
            "28c9be87c281459abfc211cecf4c9d3f",
            "9d39f91618c64a8daba2bfe1661272b2",
            "88eb78e858484602b8a29331d257d456",
            "63f0090c072c4715bd40ccfb42062b74",
            "238fbd303461477d8382836df1f286a0",
            "5237a30c5e394477b2d886e84a96df78",
            "4fef8ae7b2ab4f2f87989ff75dcc2f52"
          ]
        },
        "id": "nX4lpUlgS6zI",
        "outputId": "1afaf621-ece8-40f0-82a6-3c45839d9f93"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221209_004521-10lxckm2</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/patrickc410/bert-multitask/runs/10lxckm2\" target=\"_blank\">gallant-shape-4</a></strong> to <a href=\"https://wandb.ai/patrickc410/bert-multitask\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Loaded tokenizer\n",
            "INFO:root:Loaded all data of length 31799\n",
            "INFO:root:Made train (length 22260), validation (length 3180), and test (length 6359) data split\n",
            "INFO:root:Made data loaders\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "INFO:root:Loaded model with 66461702 trainable parameters\n",
            "INFO:root:Created loss criterion and optimizer\n",
            "INFO:root:[CrossEntropyLoss(), CrossEntropyLoss()]\n",
            "INFO:root:Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: False\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    weight_decay: 0.0001\n",
            "\n",
            "Parameter Group 1\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: False\n",
            "    lr: 2e-05\n",
            "    maximize: False\n",
            "    weight_decay: 0.0001\n",
            ")\n",
            "INFO:root:Finished make() function\n",
            "INFO:root:BERTMultitask(\n",
            "  (pretrained_layers): DistilBertModel(\n",
            "    (embeddings): Embeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (transformer): Transformer(\n",
            "      (layer): ModuleList(\n",
            "        (0): TransformerBlock(\n",
            "          (attention): MultiHeadSelfAttention(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (ffn): FFN(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (activation): GELUActivation()\n",
            "          )\n",
            "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "        (1): TransformerBlock(\n",
            "          (attention): MultiHeadSelfAttention(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (ffn): FFN(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (activation): GELUActivation()\n",
            "          )\n",
            "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "        (2): TransformerBlock(\n",
            "          (attention): MultiHeadSelfAttention(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (ffn): FFN(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (activation): GELUActivation()\n",
            "          )\n",
            "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "        (3): TransformerBlock(\n",
            "          (attention): MultiHeadSelfAttention(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (ffn): FFN(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (activation): GELUActivation()\n",
            "          )\n",
            "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "        (4): TransformerBlock(\n",
            "          (attention): MultiHeadSelfAttention(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (ffn): FFN(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (activation): GELUActivation()\n",
            "          )\n",
            "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "        (5): TransformerBlock(\n",
            "          (attention): MultiHeadSelfAttention(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (ffn): FFN(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (activation): GELUActivation()\n",
            "          )\n",
            "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (heads): ModuleList(\n",
            "    (head0): Sequential(\n",
            "      (fc_1): Linear(in_features=768, out_features=64, bias=True)\n",
            "      (relu_1): ReLU()\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (fc_2): Linear(in_features=64, out_features=3, bias=True)\n",
            "    )\n",
            "    (head1): Sequential(\n",
            "      (fc_1): Linear(in_features=768, out_features=64, bias=True)\n",
            "      (relu_1): ReLU()\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (fc_2): Linear(in_features=64, out_features=3, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]INFO:root:Epoch 0, Training   apv           loss   after 00019 batches: 1.046\n",
            "INFO:root:Epoch 0, Training   apv           acc    after 00019 batches: 0.500\n",
            "INFO:root:Epoch 0, Training   apv           f1     after 00019 batches: 0.222\n",
            "INFO:root:Epoch 0, Training   scv           loss   after 00019 batches: 1.097\n",
            "INFO:root:Epoch 0, Training   scv           acc    after 00019 batches: 0.375\n",
            "INFO:root:Epoch 0, Training   scv           f1     after 00019 batches: 0.186\n",
            "INFO:root:Epoch 0, Training   apv           loss   after 00039 batches: 0.646\n",
            "INFO:root:Epoch 0, Training   apv           acc    after 00039 batches: 0.750\n",
            "INFO:root:Epoch 0, Training   apv           f1     after 00039 batches: 0.286\n",
            "INFO:root:Epoch 0, Training   scv           loss   after 00039 batches: 0.813\n",
            "INFO:root:Epoch 0, Training   scv           acc    after 00039 batches: 0.594\n",
            "INFO:root:Epoch 0, Training   scv           f1     after 00039 batches: 0.248\n",
            "INFO:root:Epoch 0, Training   apv           loss   after 00059 batches: 0.612\n",
            "INFO:root:Epoch 0, Training   apv           acc    after 00059 batches: 0.656\n",
            "INFO:root:Epoch 0, Training   apv           f1     after 00059 batches: 0.442\n",
            "INFO:root:Epoch 0, Training   scv           loss   after 00059 batches: 0.737\n",
            "INFO:root:Epoch 0, Training   scv           acc    after 00059 batches: 0.781\n",
            "INFO:root:Epoch 0, Training   scv           f1     after 00059 batches: 0.565\n",
            "INFO:root:Epoch 0, Training   apv           loss   after 00079 batches: 0.253\n",
            "INFO:root:Epoch 0, Training   apv           acc    after 00079 batches: 0.938\n",
            "INFO:root:Epoch 0, Training   apv           f1     after 00079 batches: 0.844\n",
            "INFO:root:Epoch 0, Training   scv           loss   after 00079 batches: 0.273\n",
            "INFO:root:Epoch 0, Training   scv           acc    after 00079 batches: 0.875\n",
            "INFO:root:Epoch 0, Training   scv           f1     after 00079 batches: 0.759\n",
            "INFO:root:Epoch 0, Training   apv           loss   after 00099 batches: 0.176\n",
            "INFO:root:Epoch 0, Training   apv           acc    after 00099 batches: 0.938\n",
            "INFO:root:Epoch 0, Training   apv           f1     after 00099 batches: 0.852\n",
            "INFO:root:Epoch 0, Training   scv           loss   after 00099 batches: 0.620\n",
            "INFO:root:Epoch 0, Training   scv           acc    after 00099 batches: 0.781\n",
            "INFO:root:Epoch 0, Training   scv           f1     after 00099 batches: 0.663\n",
            "INFO:root:Epoch 0, Training   apv           loss   after 00119 batches: 0.209\n",
            "INFO:root:Epoch 0, Training   apv           acc    after 00119 batches: 0.969\n",
            "INFO:root:Epoch 0, Training   apv           f1     after 00119 batches: 0.917\n",
            "INFO:root:Epoch 0, Training   scv           loss   after 00119 batches: 0.358\n",
            "INFO:root:Epoch 0, Training   scv           acc    after 00119 batches: 0.875\n",
            "INFO:root:Epoch 0, Training   scv           f1     after 00119 batches: 0.787\n",
            "INFO:root:Epoch 0, Training   apv           loss   after 00139 batches: 0.159\n",
            "INFO:root:Epoch 0, Training   apv           acc    after 00139 batches: 0.969\n",
            "INFO:root:Epoch 0, Training   apv           f1     after 00139 batches: 0.941\n",
            "INFO:root:Epoch 0, Training   scv           loss   after 00139 batches: 0.256\n",
            "INFO:root:Epoch 0, Training   scv           acc    after 00139 batches: 0.875\n",
            "INFO:root:Epoch 0, Training   scv           f1     after 00139 batches: 0.839\n",
            "INFO:root:Epoch 0, Training   apv           loss   after 00159 batches: 0.234\n",
            "INFO:root:Epoch 0, Training   apv           acc    after 00159 batches: 0.875\n",
            "INFO:root:Epoch 0, Training   apv           f1     after 00159 batches: 0.682\n",
            "INFO:root:Epoch 0, Training   scv           loss   after 00159 batches: 0.387\n",
            "INFO:root:Epoch 0, Training   scv           acc    after 00159 batches: 0.812\n",
            "INFO:root:Epoch 0, Training   scv           f1     after 00159 batches: 0.782\n",
            "INFO:root:Epoch 0, Training   apv           loss   after 00179 batches: 0.253\n",
            "INFO:root:Epoch 0, Training   apv           acc    after 00179 batches: 0.969\n",
            "INFO:root:Epoch 0, Training   apv           f1     after 00179 batches: 0.976\n",
            "INFO:root:Epoch 0, Training   scv           loss   after 00179 batches: 0.257\n",
            "INFO:root:Epoch 0, Training   scv           acc    after 00179 batches: 0.969\n",
            "INFO:root:Epoch 0, Training   scv           f1     after 00179 batches: 0.976\n",
            "INFO:root:Epoch 0, Training   apv           loss   after 00199 batches: 0.116\n",
            "INFO:root:Epoch 0, Training   apv           acc    after 00199 batches: 0.969\n",
            "INFO:root:Epoch 0, Training   apv           f1     after 00199 batches: 0.978\n",
            "INFO:root:Epoch 0, Training   scv           loss   after 00199 batches: 0.054\n",
            "INFO:root:Epoch 0, Training   scv           acc    after 00199 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   scv           f1     after 00199 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   apv           loss   after 00219 batches: 0.015\n",
            "INFO:root:Epoch 0, Training   apv           acc    after 00219 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   apv           f1     after 00219 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   scv           loss   after 00219 batches: 0.204\n",
            "INFO:root:Epoch 0, Training   scv           acc    after 00219 batches: 0.906\n",
            "INFO:root:Epoch 0, Training   scv           f1     after 00219 batches: 0.897\n",
            "INFO:root:Epoch 0, Training   apv           loss   after 00239 batches: 0.142\n",
            "INFO:root:Epoch 0, Training   apv           acc    after 00239 batches: 0.969\n",
            "INFO:root:Epoch 0, Training   apv           f1     after 00239 batches: 0.974\n",
            "INFO:root:Epoch 0, Training   scv           loss   after 00239 batches: 0.171\n",
            "INFO:root:Epoch 0, Training   scv           acc    after 00239 batches: 0.938\n",
            "INFO:root:Epoch 0, Training   scv           f1     after 00239 batches: 0.933\n",
            "INFO:root:Epoch 0, Training   apv           loss   after 00259 batches: 0.034\n",
            "INFO:root:Epoch 0, Training   apv           acc    after 00259 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   apv           f1     after 00259 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   scv           loss   after 00259 batches: 0.135\n",
            "INFO:root:Epoch 0, Training   scv           acc    after 00259 batches: 0.969\n",
            "INFO:root:Epoch 0, Training   scv           f1     after 00259 batches: 0.978\n",
            "INFO:root:Epoch 0, Training   apv           loss   after 00279 batches: 0.055\n",
            "INFO:root:Epoch 0, Training   apv           acc    after 00279 batches: 0.969\n",
            "INFO:root:Epoch 0, Training   apv           f1     after 00279 batches: 0.937\n",
            "INFO:root:Epoch 0, Training   scv           loss   after 00279 batches: 0.040\n",
            "INFO:root:Epoch 0, Training   scv           acc    after 00279 batches: 0.969\n",
            "INFO:root:Epoch 0, Training   scv           f1     after 00279 batches: 0.949\n",
            "INFO:root:Epoch 0, Training   apv           loss   after 00299 batches: 0.135\n",
            "INFO:root:Epoch 0, Training   apv           acc    after 00299 batches: 0.969\n",
            "INFO:root:Epoch 0, Training   apv           f1     after 00299 batches: 0.937\n",
            "INFO:root:Epoch 0, Training   scv           loss   after 00299 batches: 0.152\n",
            "INFO:root:Epoch 0, Training   scv           acc    after 00299 batches: 0.969\n",
            "INFO:root:Epoch 0, Training   scv           f1     after 00299 batches: 0.965\n",
            "INFO:root:Epoch 0, Training   apv           loss   after 00319 batches: 0.005\n",
            "INFO:root:Epoch 0, Training   apv           acc    after 00319 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   apv           f1     after 00319 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   scv           loss   after 00319 batches: 0.015\n",
            "INFO:root:Epoch 0, Training   scv           acc    after 00319 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   scv           f1     after 00319 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   apv           loss   after 00339 batches: 0.030\n",
            "INFO:root:Epoch 0, Training   apv           acc    after 00339 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   apv           f1     after 00339 batches: 0.667\n",
            "INFO:root:Epoch 0, Training   scv           loss   after 00339 batches: 0.145\n",
            "INFO:root:Epoch 0, Training   scv           acc    after 00339 batches: 0.938\n",
            "INFO:root:Epoch 0, Training   scv           f1     after 00339 batches: 0.888\n",
            "INFO:root:Epoch 0, Training   apv           loss   after 00359 batches: 0.119\n",
            "INFO:root:Epoch 0, Training   apv           acc    after 00359 batches: 0.938\n",
            "INFO:root:Epoch 0, Training   apv           f1     after 00359 batches: 0.822\n",
            "INFO:root:Epoch 0, Training   scv           loss   after 00359 batches: 0.108\n",
            "INFO:root:Epoch 0, Training   scv           acc    after 00359 batches: 0.969\n",
            "INFO:root:Epoch 0, Training   scv           f1     after 00359 batches: 0.915\n",
            "INFO:root:Epoch 0, Training   apv           loss   after 00379 batches: 0.063\n",
            "INFO:root:Epoch 0, Training   apv           acc    after 00379 batches: 0.969\n",
            "INFO:root:Epoch 0, Training   apv           f1     after 00379 batches: 0.972\n",
            "INFO:root:Epoch 0, Training   scv           loss   after 00379 batches: 0.027\n",
            "INFO:root:Epoch 0, Training   scv           acc    after 00379 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   scv           f1     after 00379 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   apv           loss   after 00399 batches: 0.171\n",
            "INFO:root:Epoch 0, Training   apv           acc    after 00399 batches: 0.969\n",
            "INFO:root:Epoch 0, Training   apv           f1     after 00399 batches: 0.954\n",
            "INFO:root:Epoch 0, Training   scv           loss   after 00399 batches: 0.031\n",
            "INFO:root:Epoch 0, Training   scv           acc    after 00399 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   scv           f1     after 00399 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   apv           loss   after 00419 batches: 0.152\n",
            "INFO:root:Epoch 0, Training   apv           acc    after 00419 batches: 0.969\n",
            "INFO:root:Epoch 0, Training   apv           f1     after 00419 batches: 0.967\n",
            "INFO:root:Epoch 0, Training   scv           loss   after 00419 batches: 0.145\n",
            "INFO:root:Epoch 0, Training   scv           acc    after 00419 batches: 0.969\n",
            "INFO:root:Epoch 0, Training   scv           f1     after 00419 batches: 0.973\n",
            "INFO:root:Epoch 0, Training   apv           loss   after 00439 batches: 0.010\n",
            "INFO:root:Epoch 0, Training   apv           acc    after 00439 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   apv           f1     after 00439 batches: 0.667\n",
            "INFO:root:Epoch 0, Training   scv           loss   after 00439 batches: 0.122\n",
            "INFO:root:Epoch 0, Training   scv           acc    after 00439 batches: 0.969\n",
            "INFO:root:Epoch 0, Training   scv           f1     after 00439 batches: 0.651\n",
            "INFO:root:Epoch 0, Training   apv           loss   after 00459 batches: 0.026\n",
            "INFO:root:Epoch 0, Training   apv           acc    after 00459 batches: 0.969\n",
            "INFO:root:Epoch 0, Training   apv           f1     after 00459 batches: 0.927\n",
            "INFO:root:Epoch 0, Training   scv           loss   after 00459 batches: 0.023\n",
            "INFO:root:Epoch 0, Training   scv           acc    after 00459 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   scv           f1     after 00459 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   apv           loss   after 00479 batches: 0.084\n",
            "INFO:root:Epoch 0, Training   apv           acc    after 00479 batches: 0.969\n",
            "INFO:root:Epoch 0, Training   apv           f1     after 00479 batches: 0.945\n",
            "INFO:root:Epoch 0, Training   scv           loss   after 00479 batches: 0.210\n",
            "INFO:root:Epoch 0, Training   scv           acc    after 00479 batches: 0.906\n",
            "INFO:root:Epoch 0, Training   scv           f1     after 00479 batches: 0.902\n",
            "INFO:root:Epoch 0, Training   apv           loss   after 00499 batches: 0.005\n",
            "INFO:root:Epoch 0, Training   apv           acc    after 00499 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   apv           f1     after 00499 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   scv           loss   after 00499 batches: 0.014\n",
            "INFO:root:Epoch 0, Training   scv           acc    after 00499 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   scv           f1     after 00499 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   apv           loss   after 00519 batches: 0.016\n",
            "INFO:root:Epoch 0, Training   apv           acc    after 00519 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   apv           f1     after 00519 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   scv           loss   after 00519 batches: 0.113\n",
            "INFO:root:Epoch 0, Training   scv           acc    after 00519 batches: 0.969\n",
            "INFO:root:Epoch 0, Training   scv           f1     after 00519 batches: 0.961\n",
            "INFO:root:Epoch 0, Training   apv           loss   after 00539 batches: 0.007\n",
            "INFO:root:Epoch 0, Training   apv           acc    after 00539 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   apv           f1     after 00539 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   scv           loss   after 00539 batches: 0.011\n",
            "INFO:root:Epoch 0, Training   scv           acc    after 00539 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   scv           f1     after 00539 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   apv           loss   after 00559 batches: 0.003\n",
            "INFO:root:Epoch 0, Training   apv           acc    after 00559 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   apv           f1     after 00559 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   scv           loss   after 00559 batches: 0.007\n",
            "INFO:root:Epoch 0, Training   scv           acc    after 00559 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   scv           f1     after 00559 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   apv           loss   after 00579 batches: 0.010\n",
            "INFO:root:Epoch 0, Training   apv           acc    after 00579 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   apv           f1     after 00579 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   scv           loss   after 00579 batches: 0.050\n",
            "INFO:root:Epoch 0, Training   scv           acc    after 00579 batches: 0.969\n",
            "INFO:root:Epoch 0, Training   scv           f1     after 00579 batches: 0.933\n",
            "INFO:root:Epoch 0, Training   apv           loss   after 00599 batches: 0.071\n",
            "INFO:root:Epoch 0, Training   apv           acc    after 00599 batches: 0.969\n",
            "INFO:root:Epoch 0, Training   apv           f1     after 00599 batches: 0.976\n",
            "INFO:root:Epoch 0, Training   scv           loss   after 00599 batches: 0.076\n",
            "INFO:root:Epoch 0, Training   scv           acc    after 00599 batches: 0.969\n",
            "INFO:root:Epoch 0, Training   scv           f1     after 00599 batches: 0.975\n",
            "INFO:root:Epoch 0, Training   apv           loss   after 00619 batches: 0.051\n",
            "INFO:root:Epoch 0, Training   apv           acc    after 00619 batches: 0.969\n",
            "INFO:root:Epoch 0, Training   apv           f1     after 00619 batches: 0.935\n",
            "INFO:root:Epoch 0, Training   scv           loss   after 00619 batches: 0.205\n",
            "INFO:root:Epoch 0, Training   scv           acc    after 00619 batches: 0.938\n",
            "INFO:root:Epoch 0, Training   scv           f1     after 00619 batches: 0.913\n",
            "INFO:root:Epoch 0, Training   apv           loss   after 00639 batches: 0.028\n",
            "INFO:root:Epoch 0, Training   apv           acc    after 00639 batches: 0.969\n",
            "INFO:root:Epoch 0, Training   apv           f1     after 00639 batches: 0.937\n",
            "INFO:root:Epoch 0, Training   scv           loss   after 00639 batches: 0.041\n",
            "INFO:root:Epoch 0, Training   scv           acc    after 00639 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   scv           f1     after 00639 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   apv           loss   after 00659 batches: 0.004\n",
            "INFO:root:Epoch 0, Training   apv           acc    after 00659 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   apv           f1     after 00659 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   scv           loss   after 00659 batches: 0.013\n",
            "INFO:root:Epoch 0, Training   scv           acc    after 00659 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   scv           f1     after 00659 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   apv           loss   after 00679 batches: 0.151\n",
            "INFO:root:Epoch 0, Training   apv           acc    after 00679 batches: 0.938\n",
            "INFO:root:Epoch 0, Training   apv           f1     after 00679 batches: 0.896\n",
            "INFO:root:Epoch 0, Training   scv           loss   after 00679 batches: 0.051\n",
            "INFO:root:Epoch 0, Training   scv           acc    after 00679 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   scv           f1     after 00679 batches: 1.000\n",
            "INFO:root:Epoch 0, Training   apv           loss   after 00696 batches: 0.148\n",
            "INFO:root:Epoch 0, Training   apv           acc    after 00696 batches: 0.947\n",
            "INFO:root:Epoch 0, Training   apv           f1     after 00696 batches: 0.876\n",
            "INFO:root:Epoch 0, Training   scv           loss   after 00696 batches: 0.209\n",
            "INFO:root:Epoch 0, Training   scv           acc    after 00696 batches: 0.918\n",
            "INFO:root:Epoch 0, Training   scv           f1     after 00696 batches: 0.868\n",
            "INFO:root:Epoch 0, Validation apv          acc    after 00696 batches: 0.986\n",
            "INFO:root:Epoch 0, Validation apv          f1     after 00696 batches: 0.977\n",
            "INFO:root:Epoch 0, Validation scv          acc    after 00696 batches: 0.973\n",
            "INFO:root:Epoch 0, Validation scv          f1     after 00696 batches: 0.965\n",
            " 33%|███▎      | 1/3 [04:18<08:37, 258.85s/it]INFO:root:Epoch 1, Training   apv           loss   after 00699 batches: 0.003\n",
            "INFO:root:Epoch 1, Training   apv           acc    after 00699 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           f1     after 00699 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           loss   after 00699 batches: 0.006\n",
            "INFO:root:Epoch 1, Training   scv           acc    after 00699 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           f1     after 00699 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           loss   after 00719 batches: 0.004\n",
            "INFO:root:Epoch 1, Training   apv           acc    after 00719 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           f1     after 00719 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           loss   after 00719 batches: 0.015\n",
            "INFO:root:Epoch 1, Training   scv           acc    after 00719 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           f1     after 00719 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           loss   after 00739 batches: 0.011\n",
            "INFO:root:Epoch 1, Training   apv           acc    after 00739 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           f1     after 00739 batches: 0.667\n",
            "INFO:root:Epoch 1, Training   scv           loss   after 00739 batches: 0.021\n",
            "INFO:root:Epoch 1, Training   scv           acc    after 00739 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           f1     after 00739 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           loss   after 00759 batches: 0.193\n",
            "INFO:root:Epoch 1, Training   apv           acc    after 00759 batches: 0.969\n",
            "INFO:root:Epoch 1, Training   apv           f1     after 00759 batches: 0.946\n",
            "INFO:root:Epoch 1, Training   scv           loss   after 00759 batches: 0.139\n",
            "INFO:root:Epoch 1, Training   scv           acc    after 00759 batches: 0.938\n",
            "INFO:root:Epoch 1, Training   scv           f1     after 00759 batches: 0.910\n",
            "INFO:root:Epoch 1, Training   apv           loss   after 00779 batches: 0.014\n",
            "INFO:root:Epoch 1, Training   apv           acc    after 00779 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           f1     after 00779 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           loss   after 00779 batches: 0.009\n",
            "INFO:root:Epoch 1, Training   scv           acc    after 00779 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           f1     after 00779 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           loss   after 00799 batches: 0.012\n",
            "INFO:root:Epoch 1, Training   apv           acc    after 00799 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           f1     after 00799 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           loss   after 00799 batches: 0.020\n",
            "INFO:root:Epoch 1, Training   scv           acc    after 00799 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           f1     after 00799 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           loss   after 00819 batches: 0.060\n",
            "INFO:root:Epoch 1, Training   apv           acc    after 00819 batches: 0.969\n",
            "INFO:root:Epoch 1, Training   apv           f1     after 00819 batches: 0.905\n",
            "INFO:root:Epoch 1, Training   scv           loss   after 00819 batches: 0.043\n",
            "INFO:root:Epoch 1, Training   scv           acc    after 00819 batches: 0.969\n",
            "INFO:root:Epoch 1, Training   scv           f1     after 00819 batches: 0.915\n",
            "INFO:root:Epoch 1, Training   apv           loss   after 00839 batches: 0.235\n",
            "INFO:root:Epoch 1, Training   apv           acc    after 00839 batches: 0.906\n",
            "INFO:root:Epoch 1, Training   apv           f1     after 00839 batches: 0.832\n",
            "INFO:root:Epoch 1, Training   scv           loss   after 00839 batches: 0.252\n",
            "INFO:root:Epoch 1, Training   scv           acc    after 00839 batches: 0.906\n",
            "INFO:root:Epoch 1, Training   scv           f1     after 00839 batches: 0.845\n",
            "INFO:root:Epoch 1, Training   apv           loss   after 00859 batches: 0.003\n",
            "INFO:root:Epoch 1, Training   apv           acc    after 00859 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           f1     after 00859 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           loss   after 00859 batches: 0.008\n",
            "INFO:root:Epoch 1, Training   scv           acc    after 00859 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           f1     after 00859 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           loss   after 00879 batches: 0.011\n",
            "INFO:root:Epoch 1, Training   apv           acc    after 00879 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           f1     after 00879 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           loss   after 00879 batches: 0.025\n",
            "INFO:root:Epoch 1, Training   scv           acc    after 00879 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           f1     after 00879 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           loss   after 00899 batches: 0.221\n",
            "INFO:root:Epoch 1, Training   apv           acc    after 00899 batches: 0.938\n",
            "INFO:root:Epoch 1, Training   apv           f1     after 00899 batches: 0.869\n",
            "INFO:root:Epoch 1, Training   scv           loss   after 00899 batches: 0.189\n",
            "INFO:root:Epoch 1, Training   scv           acc    after 00899 batches: 0.969\n",
            "INFO:root:Epoch 1, Training   scv           f1     after 00899 batches: 0.960\n",
            "INFO:root:Epoch 1, Training   apv           loss   after 00919 batches: 0.017\n",
            "INFO:root:Epoch 1, Training   apv           acc    after 00919 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           f1     after 00919 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           loss   after 00919 batches: 0.031\n",
            "INFO:root:Epoch 1, Training   scv           acc    after 00919 batches: 0.969\n",
            "INFO:root:Epoch 1, Training   scv           f1     after 00919 batches: 0.974\n",
            "INFO:root:Epoch 1, Training   apv           loss   after 00939 batches: 0.004\n",
            "INFO:root:Epoch 1, Training   apv           acc    after 00939 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           f1     after 00939 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           loss   after 00939 batches: 0.057\n",
            "INFO:root:Epoch 1, Training   scv           acc    after 00939 batches: 0.969\n",
            "INFO:root:Epoch 1, Training   scv           f1     after 00939 batches: 0.955\n",
            "INFO:root:Epoch 1, Training   apv           loss   after 00959 batches: 0.032\n",
            "INFO:root:Epoch 1, Training   apv           acc    after 00959 batches: 0.969\n",
            "INFO:root:Epoch 1, Training   apv           f1     after 00959 batches: 0.641\n",
            "INFO:root:Epoch 1, Training   scv           loss   after 00959 batches: 0.015\n",
            "INFO:root:Epoch 1, Training   scv           acc    after 00959 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           f1     after 00959 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           loss   after 00979 batches: 0.004\n",
            "INFO:root:Epoch 1, Training   apv           acc    after 00979 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           f1     after 00979 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           loss   after 00979 batches: 0.012\n",
            "INFO:root:Epoch 1, Training   scv           acc    after 00979 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           f1     after 00979 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           loss   after 00999 batches: 0.001\n",
            "INFO:root:Epoch 1, Training   apv           acc    after 00999 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           f1     after 00999 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           loss   after 00999 batches: 0.006\n",
            "INFO:root:Epoch 1, Training   scv           acc    after 00999 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           f1     after 00999 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           loss   after 01019 batches: 0.004\n",
            "INFO:root:Epoch 1, Training   apv           acc    after 01019 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           f1     after 01019 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           loss   after 01019 batches: 0.041\n",
            "INFO:root:Epoch 1, Training   scv           acc    after 01019 batches: 0.969\n",
            "INFO:root:Epoch 1, Training   scv           f1     after 01019 batches: 0.954\n",
            "INFO:root:Epoch 1, Training   apv           loss   after 01039 batches: 0.004\n",
            "INFO:root:Epoch 1, Training   apv           acc    after 01039 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           f1     after 01039 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           loss   after 01039 batches: 0.062\n",
            "INFO:root:Epoch 1, Training   scv           acc    after 01039 batches: 0.969\n",
            "INFO:root:Epoch 1, Training   scv           f1     after 01039 batches: 0.975\n",
            "INFO:root:Epoch 1, Training   apv           loss   after 01059 batches: 0.021\n",
            "INFO:root:Epoch 1, Training   apv           acc    after 01059 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           f1     after 01059 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           loss   after 01059 batches: 0.021\n",
            "INFO:root:Epoch 1, Training   scv           acc    after 01059 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           f1     after 01059 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           loss   after 01079 batches: 0.021\n",
            "INFO:root:Epoch 1, Training   apv           acc    after 01079 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           f1     after 01079 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           loss   after 01079 batches: 0.009\n",
            "INFO:root:Epoch 1, Training   scv           acc    after 01079 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           f1     after 01079 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           loss   after 01099 batches: 0.010\n",
            "INFO:root:Epoch 1, Training   apv           acc    after 01099 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           f1     after 01099 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           loss   after 01099 batches: 0.034\n",
            "INFO:root:Epoch 1, Training   scv           acc    after 01099 batches: 0.969\n",
            "INFO:root:Epoch 1, Training   scv           f1     after 01099 batches: 0.951\n",
            "INFO:root:Epoch 1, Training   apv           loss   after 01119 batches: 0.127\n",
            "INFO:root:Epoch 1, Training   apv           acc    after 01119 batches: 0.969\n",
            "INFO:root:Epoch 1, Training   apv           f1     after 01119 batches: 0.968\n",
            "INFO:root:Epoch 1, Training   scv           loss   after 01119 batches: 0.162\n",
            "INFO:root:Epoch 1, Training   scv           acc    after 01119 batches: 0.938\n",
            "INFO:root:Epoch 1, Training   scv           f1     after 01119 batches: 0.907\n",
            "INFO:root:Epoch 1, Training   apv           loss   after 01139 batches: 0.019\n",
            "INFO:root:Epoch 1, Training   apv           acc    after 01139 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           f1     after 01139 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           loss   after 01139 batches: 0.028\n",
            "INFO:root:Epoch 1, Training   scv           acc    after 01139 batches: 0.969\n",
            "INFO:root:Epoch 1, Training   scv           f1     after 01139 batches: 0.952\n",
            "INFO:root:Epoch 1, Training   apv           loss   after 01159 batches: 0.008\n",
            "INFO:root:Epoch 1, Training   apv           acc    after 01159 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           f1     after 01159 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           loss   after 01159 batches: 0.012\n",
            "INFO:root:Epoch 1, Training   scv           acc    after 01159 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           f1     after 01159 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           loss   after 01179 batches: 0.002\n",
            "INFO:root:Epoch 1, Training   apv           acc    after 01179 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           f1     after 01179 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           loss   after 01179 batches: 0.007\n",
            "INFO:root:Epoch 1, Training   scv           acc    after 01179 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           f1     after 01179 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           loss   after 01199 batches: 0.015\n",
            "INFO:root:Epoch 1, Training   apv           acc    after 01199 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           f1     after 01199 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           loss   after 01199 batches: 0.020\n",
            "INFO:root:Epoch 1, Training   scv           acc    after 01199 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           f1     after 01199 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           loss   after 01219 batches: 0.008\n",
            "INFO:root:Epoch 1, Training   apv           acc    after 01219 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           f1     after 01219 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           loss   after 01219 batches: 0.004\n",
            "INFO:root:Epoch 1, Training   scv           acc    after 01219 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           f1     after 01219 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           loss   after 01239 batches: 0.004\n",
            "INFO:root:Epoch 1, Training   apv           acc    after 01239 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           f1     after 01239 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           loss   after 01239 batches: 0.007\n",
            "INFO:root:Epoch 1, Training   scv           acc    after 01239 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           f1     after 01239 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           loss   after 01259 batches: 0.001\n",
            "INFO:root:Epoch 1, Training   apv           acc    after 01259 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           f1     after 01259 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           loss   after 01259 batches: 0.095\n",
            "INFO:root:Epoch 1, Training   scv           acc    after 01259 batches: 0.969\n",
            "INFO:root:Epoch 1, Training   scv           f1     after 01259 batches: 0.957\n",
            "INFO:root:Epoch 1, Training   apv           loss   after 01279 batches: 0.039\n",
            "INFO:root:Epoch 1, Training   apv           acc    after 01279 batches: 0.969\n",
            "INFO:root:Epoch 1, Training   apv           f1     after 01279 batches: 0.965\n",
            "INFO:root:Epoch 1, Training   scv           loss   after 01279 batches: 0.077\n",
            "INFO:root:Epoch 1, Training   scv           acc    after 01279 batches: 0.969\n",
            "INFO:root:Epoch 1, Training   scv           f1     after 01279 batches: 0.960\n",
            "INFO:root:Epoch 1, Training   apv           loss   after 01299 batches: 0.000\n",
            "INFO:root:Epoch 1, Training   apv           acc    after 01299 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           f1     after 01299 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           loss   after 01299 batches: 0.034\n",
            "INFO:root:Epoch 1, Training   scv           acc    after 01299 batches: 0.969\n",
            "INFO:root:Epoch 1, Training   scv           f1     after 01299 batches: 0.922\n",
            "INFO:root:Epoch 1, Training   apv           loss   after 01319 batches: 0.047\n",
            "INFO:root:Epoch 1, Training   apv           acc    after 01319 batches: 0.969\n",
            "INFO:root:Epoch 1, Training   apv           f1     after 01319 batches: 0.962\n",
            "INFO:root:Epoch 1, Training   scv           loss   after 01319 batches: 0.006\n",
            "INFO:root:Epoch 1, Training   scv           acc    after 01319 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           f1     after 01319 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           loss   after 01339 batches: 0.012\n",
            "INFO:root:Epoch 1, Training   apv           acc    after 01339 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           f1     after 01339 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           loss   after 01339 batches: 0.142\n",
            "INFO:root:Epoch 1, Training   scv           acc    after 01339 batches: 0.938\n",
            "INFO:root:Epoch 1, Training   scv           f1     after 01339 batches: 0.903\n",
            "INFO:root:Epoch 1, Training   apv           loss   after 01359 batches: 0.045\n",
            "INFO:root:Epoch 1, Training   apv           acc    after 01359 batches: 0.969\n",
            "INFO:root:Epoch 1, Training   apv           f1     after 01359 batches: 0.973\n",
            "INFO:root:Epoch 1, Training   scv           loss   after 01359 batches: 0.077\n",
            "INFO:root:Epoch 1, Training   scv           acc    after 01359 batches: 0.969\n",
            "INFO:root:Epoch 1, Training   scv           f1     after 01359 batches: 0.975\n",
            "INFO:root:Epoch 1, Training   apv           loss   after 01379 batches: 0.016\n",
            "INFO:root:Epoch 1, Training   apv           acc    after 01379 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           f1     after 01379 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           loss   after 01379 batches: 0.005\n",
            "INFO:root:Epoch 1, Training   scv           acc    after 01379 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   scv           f1     after 01379 batches: 1.000\n",
            "INFO:root:Epoch 1, Training   apv           loss   after 01392 batches: 0.035\n",
            "INFO:root:Epoch 1, Training   apv           acc    after 01392 batches: 0.990\n",
            "INFO:root:Epoch 1, Training   apv           f1     after 01392 batches: 0.966\n",
            "INFO:root:Epoch 1, Training   scv           loss   after 01392 batches: 0.060\n",
            "INFO:root:Epoch 1, Training   scv           acc    after 01392 batches: 0.983\n",
            "INFO:root:Epoch 1, Training   scv           f1     after 01392 batches: 0.973\n",
            "INFO:root:Epoch 1, Validation apv          acc    after 01392 batches: 0.989\n",
            "INFO:root:Epoch 1, Validation apv          f1     after 01392 batches: 0.983\n",
            "INFO:root:Epoch 1, Validation scv          acc    after 01392 batches: 0.981\n",
            "INFO:root:Epoch 1, Validation scv          f1     after 01392 batches: 0.976\n",
            " 67%|██████▋   | 2/3 [08:37<04:18, 258.57s/it]INFO:root:Epoch 2, Training   apv           loss   after 01399 batches: 0.008\n",
            "INFO:root:Epoch 2, Training   apv           acc    after 01399 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           f1     after 01399 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           loss   after 01399 batches: 0.033\n",
            "INFO:root:Epoch 2, Training   scv           acc    after 01399 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           f1     after 01399 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           loss   after 01419 batches: 0.001\n",
            "INFO:root:Epoch 2, Training   apv           acc    after 01419 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           f1     after 01419 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           loss   after 01419 batches: 0.010\n",
            "INFO:root:Epoch 2, Training   scv           acc    after 01419 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           f1     after 01419 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           loss   after 01439 batches: 0.015\n",
            "INFO:root:Epoch 2, Training   apv           acc    after 01439 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           f1     after 01439 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           loss   after 01439 batches: 0.028\n",
            "INFO:root:Epoch 2, Training   scv           acc    after 01439 batches: 0.969\n",
            "INFO:root:Epoch 2, Training   scv           f1     after 01439 batches: 0.953\n",
            "INFO:root:Epoch 2, Training   apv           loss   after 01459 batches: 0.005\n",
            "INFO:root:Epoch 2, Training   apv           acc    after 01459 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           f1     after 01459 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           loss   after 01459 batches: 0.177\n",
            "INFO:root:Epoch 2, Training   scv           acc    after 01459 batches: 0.969\n",
            "INFO:root:Epoch 2, Training   scv           f1     after 01459 batches: 0.956\n",
            "INFO:root:Epoch 2, Training   apv           loss   after 01479 batches: 0.008\n",
            "INFO:root:Epoch 2, Training   apv           acc    after 01479 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           f1     after 01479 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           loss   after 01479 batches: 0.113\n",
            "INFO:root:Epoch 2, Training   scv           acc    after 01479 batches: 0.969\n",
            "INFO:root:Epoch 2, Training   scv           f1     after 01479 batches: 0.954\n",
            "INFO:root:Epoch 2, Training   apv           loss   after 01499 batches: 0.005\n",
            "INFO:root:Epoch 2, Training   apv           acc    after 01499 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           f1     after 01499 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           loss   after 01499 batches: 0.002\n",
            "INFO:root:Epoch 2, Training   scv           acc    after 01499 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           f1     after 01499 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           loss   after 01519 batches: 0.047\n",
            "INFO:root:Epoch 2, Training   apv           acc    after 01519 batches: 0.969\n",
            "INFO:root:Epoch 2, Training   apv           f1     after 01519 batches: 0.933\n",
            "INFO:root:Epoch 2, Training   scv           loss   after 01519 batches: 0.022\n",
            "INFO:root:Epoch 2, Training   scv           acc    after 01519 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           f1     after 01519 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           loss   after 01539 batches: 0.002\n",
            "INFO:root:Epoch 2, Training   apv           acc    after 01539 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           f1     after 01539 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           loss   after 01539 batches: 0.013\n",
            "INFO:root:Epoch 2, Training   scv           acc    after 01539 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           f1     after 01539 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           loss   after 01559 batches: 0.005\n",
            "INFO:root:Epoch 2, Training   apv           acc    after 01559 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           f1     after 01559 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           loss   after 01559 batches: 0.006\n",
            "INFO:root:Epoch 2, Training   scv           acc    after 01559 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           f1     after 01559 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           loss   after 01579 batches: 0.012\n",
            "INFO:root:Epoch 2, Training   apv           acc    after 01579 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           f1     after 01579 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           loss   after 01579 batches: 0.023\n",
            "INFO:root:Epoch 2, Training   scv           acc    after 01579 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           f1     after 01579 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           loss   after 01599 batches: 0.000\n",
            "INFO:root:Epoch 2, Training   apv           acc    after 01599 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           f1     after 01599 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           loss   after 01599 batches: 0.001\n",
            "INFO:root:Epoch 2, Training   scv           acc    after 01599 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           f1     after 01599 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           loss   after 01619 batches: 0.001\n",
            "INFO:root:Epoch 2, Training   apv           acc    after 01619 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           f1     after 01619 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           loss   after 01619 batches: 0.005\n",
            "INFO:root:Epoch 2, Training   scv           acc    after 01619 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           f1     after 01619 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           loss   after 01639 batches: 0.051\n",
            "INFO:root:Epoch 2, Training   apv           acc    after 01639 batches: 0.969\n",
            "INFO:root:Epoch 2, Training   apv           f1     after 01639 batches: 0.956\n",
            "INFO:root:Epoch 2, Training   scv           loss   after 01639 batches: 0.009\n",
            "INFO:root:Epoch 2, Training   scv           acc    after 01639 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           f1     after 01639 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           loss   after 01659 batches: 0.005\n",
            "INFO:root:Epoch 2, Training   apv           acc    after 01659 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           f1     after 01659 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           loss   after 01659 batches: 0.179\n",
            "INFO:root:Epoch 2, Training   scv           acc    after 01659 batches: 0.969\n",
            "INFO:root:Epoch 2, Training   scv           f1     after 01659 batches: 0.972\n",
            "INFO:root:Epoch 2, Training   apv           loss   after 01679 batches: 0.002\n",
            "INFO:root:Epoch 2, Training   apv           acc    after 01679 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           f1     after 01679 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           loss   after 01679 batches: 0.036\n",
            "INFO:root:Epoch 2, Training   scv           acc    after 01679 batches: 0.969\n",
            "INFO:root:Epoch 2, Training   scv           f1     after 01679 batches: 0.958\n",
            "INFO:root:Epoch 2, Training   apv           loss   after 01699 batches: 0.000\n",
            "INFO:root:Epoch 2, Training   apv           acc    after 01699 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           f1     after 01699 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           loss   after 01699 batches: 0.011\n",
            "INFO:root:Epoch 2, Training   scv           acc    after 01699 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           f1     after 01699 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           loss   after 01719 batches: 0.000\n",
            "INFO:root:Epoch 2, Training   apv           acc    after 01719 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           f1     after 01719 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           loss   after 01719 batches: 0.003\n",
            "INFO:root:Epoch 2, Training   scv           acc    after 01719 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           f1     after 01719 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           loss   after 01739 batches: 0.001\n",
            "INFO:root:Epoch 2, Training   apv           acc    after 01739 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           f1     after 01739 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           loss   after 01739 batches: 0.002\n",
            "INFO:root:Epoch 2, Training   scv           acc    after 01739 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           f1     after 01739 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           loss   after 01759 batches: 0.052\n",
            "INFO:root:Epoch 2, Training   apv           acc    after 01759 batches: 0.969\n",
            "INFO:root:Epoch 2, Training   apv           f1     after 01759 batches: 0.972\n",
            "INFO:root:Epoch 2, Training   scv           loss   after 01759 batches: 0.018\n",
            "INFO:root:Epoch 2, Training   scv           acc    after 01759 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           f1     after 01759 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           loss   after 01779 batches: 0.001\n",
            "INFO:root:Epoch 2, Training   apv           acc    after 01779 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           f1     after 01779 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           loss   after 01779 batches: 0.002\n",
            "INFO:root:Epoch 2, Training   scv           acc    after 01779 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           f1     after 01779 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           loss   after 01799 batches: 0.001\n",
            "INFO:root:Epoch 2, Training   apv           acc    after 01799 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           f1     after 01799 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           loss   after 01799 batches: 0.002\n",
            "INFO:root:Epoch 2, Training   scv           acc    after 01799 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           f1     after 01799 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           loss   after 01819 batches: 0.000\n",
            "INFO:root:Epoch 2, Training   apv           acc    after 01819 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           f1     after 01819 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           loss   after 01819 batches: 0.001\n",
            "INFO:root:Epoch 2, Training   scv           acc    after 01819 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           f1     after 01819 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           loss   after 01839 batches: 0.000\n",
            "INFO:root:Epoch 2, Training   apv           acc    after 01839 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           f1     after 01839 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           loss   after 01839 batches: 0.007\n",
            "INFO:root:Epoch 2, Training   scv           acc    after 01839 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           f1     after 01839 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           loss   after 01859 batches: 0.015\n",
            "INFO:root:Epoch 2, Training   apv           acc    after 01859 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           f1     after 01859 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           loss   after 01859 batches: 0.009\n",
            "INFO:root:Epoch 2, Training   scv           acc    after 01859 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           f1     after 01859 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           loss   after 01879 batches: 0.000\n",
            "INFO:root:Epoch 2, Training   apv           acc    after 01879 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           f1     after 01879 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           loss   after 01879 batches: 0.002\n",
            "INFO:root:Epoch 2, Training   scv           acc    after 01879 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           f1     after 01879 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           loss   after 01899 batches: 0.000\n",
            "INFO:root:Epoch 2, Training   apv           acc    after 01899 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           f1     after 01899 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           loss   after 01899 batches: 0.008\n",
            "INFO:root:Epoch 2, Training   scv           acc    after 01899 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           f1     after 01899 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           loss   after 01919 batches: 0.000\n",
            "INFO:root:Epoch 2, Training   apv           acc    after 01919 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           f1     after 01919 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           loss   after 01919 batches: 0.007\n",
            "INFO:root:Epoch 2, Training   scv           acc    after 01919 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           f1     after 01919 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           loss   after 01939 batches: 0.000\n",
            "INFO:root:Epoch 2, Training   apv           acc    after 01939 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           f1     after 01939 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           loss   after 01939 batches: 0.004\n",
            "INFO:root:Epoch 2, Training   scv           acc    after 01939 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           f1     after 01939 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           loss   after 01959 batches: 0.001\n",
            "INFO:root:Epoch 2, Training   apv           acc    after 01959 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           f1     after 01959 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           loss   after 01959 batches: 0.027\n",
            "INFO:root:Epoch 2, Training   scv           acc    after 01959 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           f1     after 01959 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           loss   after 01979 batches: 0.001\n",
            "INFO:root:Epoch 2, Training   apv           acc    after 01979 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           f1     after 01979 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           loss   after 01979 batches: 0.005\n",
            "INFO:root:Epoch 2, Training   scv           acc    after 01979 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           f1     after 01979 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           loss   after 01999 batches: 0.000\n",
            "INFO:root:Epoch 2, Training   apv           acc    after 01999 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           f1     after 01999 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           loss   after 01999 batches: 0.004\n",
            "INFO:root:Epoch 2, Training   scv           acc    after 01999 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           f1     after 01999 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           loss   after 02019 batches: 0.021\n",
            "INFO:root:Epoch 2, Training   apv           acc    after 02019 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           f1     after 02019 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           loss   after 02019 batches: 0.077\n",
            "INFO:root:Epoch 2, Training   scv           acc    after 02019 batches: 0.969\n",
            "INFO:root:Epoch 2, Training   scv           f1     after 02019 batches: 0.971\n",
            "INFO:root:Epoch 2, Training   apv           loss   after 02039 batches: 0.070\n",
            "INFO:root:Epoch 2, Training   apv           acc    after 02039 batches: 0.969\n",
            "INFO:root:Epoch 2, Training   apv           f1     after 02039 batches: 0.967\n",
            "INFO:root:Epoch 2, Training   scv           loss   after 02039 batches: 0.140\n",
            "INFO:root:Epoch 2, Training   scv           acc    after 02039 batches: 0.969\n",
            "INFO:root:Epoch 2, Training   scv           f1     after 02039 batches: 0.971\n",
            "INFO:root:Epoch 2, Training   apv           loss   after 02059 batches: 0.020\n",
            "INFO:root:Epoch 2, Training   apv           acc    after 02059 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           f1     after 02059 batches: 0.667\n",
            "INFO:root:Epoch 2, Training   scv           loss   after 02059 batches: 0.037\n",
            "INFO:root:Epoch 2, Training   scv           acc    after 02059 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           f1     after 02059 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           loss   after 02079 batches: 0.002\n",
            "INFO:root:Epoch 2, Training   apv           acc    after 02079 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           f1     after 02079 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           loss   after 02079 batches: 0.002\n",
            "INFO:root:Epoch 2, Training   scv           acc    after 02079 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   scv           f1     after 02079 batches: 1.000\n",
            "INFO:root:Epoch 2, Training   apv           loss   after 02088 batches: 0.016\n",
            "INFO:root:Epoch 2, Training   apv           acc    after 02088 batches: 0.995\n",
            "INFO:root:Epoch 2, Training   apv           f1     after 02088 batches: 0.976\n",
            "INFO:root:Epoch 2, Training   scv           loss   after 02088 batches: 0.036\n",
            "INFO:root:Epoch 2, Training   scv           acc    after 02088 batches: 0.991\n",
            "INFO:root:Epoch 2, Training   scv           f1     after 02088 batches: 0.983\n",
            "INFO:root:Epoch 2, Validation apv          acc    after 02088 batches: 0.989\n",
            "INFO:root:Epoch 2, Validation apv          f1     after 02088 batches: 0.985\n",
            "INFO:root:Epoch 2, Validation scv          acc    after 02088 batches: 0.981\n",
            "INFO:root:Epoch 2, Validation scv          f1     after 02088 batches: 0.977\n",
            "100%|██████████| 3/3 [12:54<00:00, 258.00s/it]\n",
            "INFO:root:Finished train() function\n",
            "INFO:root:         Test apv           acc    on the 06359 test samples: 0.989\n",
            "INFO:root:         Test apv           f1     on the 06359 test samples: 0.984\n",
            "INFO:root:         Test scv           acc    on the 06359 test samples: 0.984\n",
            "INFO:root:         Test scv           f1     on the 06359 test samples: 0.981\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3560f89e3afc421b9bc6f3c9c5f88577"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_ct</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅█████████████</td></tr><tr><td>model_n_params</td><td>▁</td></tr><tr><td>test_apv_acc</td><td>▁</td></tr><tr><td>test_apv_f1</td><td>▁</td></tr><tr><td>test_samples</td><td>▁</td></tr><tr><td>test_scv_acc</td><td>▁</td></tr><tr><td>test_scv_f1</td><td>▁</td></tr><tr><td>train_apv_acc</td><td>▁▇█</td></tr><tr><td>train_apv_f1</td><td>▁▇█</td></tr><tr><td>train_apv_loss</td><td>█▂▁</td></tr><tr><td>train_batch_apv_acc</td><td>▁▃█▆█████████████▇██████████████████████</td></tr><tr><td>train_batch_apv_f1</td><td>▁▃▇▅█▇██▅███▇█▅██▇▅█████████████████████</td></tr><tr><td>train_batch_apv_loss</td><td>█▅▂▃▁▁▁▁▁▂▁▁▁▁▁▁▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_batch_scv_acc</td><td>▁▆▇▆▇████▇███████████▇███▇██████████████</td></tr><tr><td>train_batch_scv_f1</td><td>▁▄▆▆▇███▅▇███████████▇███▇██████████████</td></tr><tr><td>train_batch_scv_loss</td><td>█▆▃▃▂▁▁▁▂▂▁▁▁▁▁▁▁▂▁▁▁▂▁▁▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_samples</td><td>▁</td></tr><tr><td>train_scv_acc</td><td>▁▇█</td></tr><tr><td>train_scv_f1</td><td>▁▇█</td></tr><tr><td>train_scv_loss</td><td>█▂▁</td></tr><tr><td>val_samples</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_ct</td><td>2088</td></tr><tr><td>epoch</td><td>2</td></tr><tr><td>model_n_params</td><td>66461702</td></tr><tr><td>test_apv_acc</td><td>0.98852</td></tr><tr><td>test_apv_f1</td><td>0.98443</td></tr><tr><td>test_samples</td><td>6359</td></tr><tr><td>test_scv_acc</td><td>0.9838</td></tr><tr><td>test_scv_f1</td><td>0.9807</td></tr><tr><td>train_apv_acc</td><td>0.99481</td></tr><tr><td>train_apv_f1</td><td>0.97567</td></tr><tr><td>train_apv_loss</td><td>0.01597</td></tr><tr><td>train_batch_apv_acc</td><td>1.0</td></tr><tr><td>train_batch_apv_f1</td><td>1.0</td></tr><tr><td>train_batch_apv_loss</td><td>0.0018</td></tr><tr><td>train_batch_scv_acc</td><td>1.0</td></tr><tr><td>train_batch_scv_f1</td><td>1.0</td></tr><tr><td>train_batch_scv_loss</td><td>0.0024</td></tr><tr><td>train_samples</td><td>22260</td></tr><tr><td>train_scv_acc</td><td>0.99053</td></tr><tr><td>train_scv_f1</td><td>0.98279</td></tr><tr><td>train_scv_loss</td><td>0.03553</td></tr><tr><td>val_samples</td><td>3180</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">gallant-shape-4</strong>: <a href=\"https://wandb.ai/patrickc410/bert-multitask/runs/10lxckm2\" target=\"_blank\">https://wandb.ai/patrickc410/bert-multitask/runs/10lxckm2</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20221209_004521-10lxckm2/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BERTMultitask(\n",
              "  (pretrained_layers): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (1): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (2): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (3): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (4): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (5): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (heads): ModuleList(\n",
              "    (head0): Sequential(\n",
              "      (fc_1): Linear(in_features=768, out_features=64, bias=True)\n",
              "      (relu_1): ReLU()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (fc_2): Linear(in_features=64, out_features=3, bias=True)\n",
              "    )\n",
              "    (head1): Sequential(\n",
              "      (fc_1): Linear(in_features=768, out_features=64, bias=True)\n",
              "      (relu_1): ReLU()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (fc_2): Linear(in_features=64, out_features=3, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "model_pipeline(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hFEcBqgZQfe"
      },
      "source": [
        "# Cleanup\n",
        "Delete source code files and data to upload newer versions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8w6YfBwTDAU"
      },
      "outputs": [],
      "source": [
        "# !rm -rf configs/ environment/ src/ results/ wandb/ nlp_proj_colab.zip pyproject.toml setup.cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36Ix623nZItP"
      },
      "outputs": [],
      "source": [
        "# !rm -rf rule_based_annotations_new_svo_dist.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test a Trained Model"
      ],
      "metadata": {
        "id": "pSFo5uzlcmj_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbG0ReQIxOer"
      },
      "outputs": [],
      "source": [
        "from nlp_proj.model_optim_utils import make_model, make_optimizer, make_criterion\n",
        "from nlp_proj.config_utils import load_config\n",
        "from nlp_proj.dataset_utils import make_dataloader, make_tokenizer, make_datasets\n",
        "from nlp_proj.train_utils_singletask import train_model_singletask, test_model_singletask\n",
        "from nlp_proj.train_utils_multitask import train_model_multitask, test_model_multitask\n",
        "from types import SimpleNamespace\n",
        "from torchmetrics.functional import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oluuc_VuxJeS"
      },
      "outputs": [],
      "source": [
        "# CONFIGURATION\n",
        "model_filepath = \"/content/results/bilstm_classifier_hv/bilstm-hv.pt\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model\n",
        "model = torch.load(model_filepath)"
      ],
      "metadata": {
        "id": "oTiGZFiGcvM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzgnAS5TVP2G",
        "outputId": "11f3edb5-1cb2-409a-dc00-bcc72aedc1cb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Loaded tokenizer\n",
            "INFO:root:Loaded all data of length 31906\n",
            "INFO:root:Made train (length 22335), validation (length 3190), and test (length 6381) data split\n",
            "INFO:root:Made data loaders\n"
          ]
        }
      ],
      "source": [
        "# Setup config\n",
        "config_ns = SimpleNamespace(**config)\n",
        "\n",
        "# Make tokenizer\n",
        "tokenizer = make_tokenizer()\n",
        "logging.info(\"Loaded tokenizer\")\n",
        "config_ns.vocab_size = tokenizer.vocab_size\n",
        "\n",
        "# Make the data loaders\n",
        "train, val, test = make_datasets(config_ns)\n",
        "train_loader = make_dataloader(train, tokenizer, config_ns)\n",
        "val_loader = make_dataloader(val, tokenizer, config_ns)\n",
        "test_loader = make_dataloader(test, tokenizer, config_ns)\n",
        "logging.info(\"Made data loaders\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zu6NOZvBVTZN"
      },
      "outputs": [],
      "source": [
        "# Test data Evaluation\n",
        "evaluation, total = test_model_singletask(model, test_loader, config_ns)\n",
        "evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNggDvgVV5Xv"
      },
      "outputs": [],
      "source": [
        "# Device\n",
        "device = config_ns.device\n",
        "model = model.to(device)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "# Run the model on some test examples\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    for batch_x, batch_y in test_loader:\n",
        "        # Push batch_x to device\n",
        "        batch_x = batch_x.to(device)\n",
        "        batch_y = batch_y.to(device)\n",
        "\n",
        "        # Forward\n",
        "        input_ids = batch_x.input_ids\n",
        "        attention_mask = batch_x.attention_mask\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # Predictions\n",
        "        if config_ns.task == \"classification\":\n",
        "            batch_preds = torch.argmax(outputs, dim=-1)\n",
        "        elif config_ns.task == \"regression\":\n",
        "            batch_preds = outputs.squeeze()\n",
        "\n",
        "        all_preds.append(batch_preds)\n",
        "        all_labels.append(batch_y)\n",
        "        total += batch_y.size(0)\n",
        "\n",
        "all_preds = torch.concat(all_preds).to(device)\n",
        "all_labels = torch.concat(all_labels).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tj8aav0AWK7n",
        "outputId": "aaa964f8-5863-4dbe-c185-3d863a66f4fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[   0,  104,    0],\n",
              "        [   0, 5932,    0],\n",
              "        [   0,  345,    0]], device='cuda:0')"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Confusion matrix \n",
        "conf = confusion_matrix(\n",
        "    all_preds, \n",
        "    all_labels, \n",
        "    task=\"multiclass\", \n",
        "    num_classes=config_ns.num_classes, \n",
        ")\n",
        "conf"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3560f89e3afc421b9bc6f3c9c5f88577": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_28c9be87c281459abfc211cecf4c9d3f",
              "IPY_MODEL_9d39f91618c64a8daba2bfe1661272b2"
            ],
            "layout": "IPY_MODEL_88eb78e858484602b8a29331d257d456"
          }
        },
        "28c9be87c281459abfc211cecf4c9d3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63f0090c072c4715bd40ccfb42062b74",
            "placeholder": "​",
            "style": "IPY_MODEL_238fbd303461477d8382836df1f286a0",
            "value": "0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "9d39f91618c64a8daba2bfe1661272b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5237a30c5e394477b2d886e84a96df78",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4fef8ae7b2ab4f2f87989ff75dcc2f52",
            "value": 1
          }
        },
        "88eb78e858484602b8a29331d257d456": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63f0090c072c4715bd40ccfb42062b74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "238fbd303461477d8382836df1f286a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5237a30c5e394477b2d886e84a96df78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fef8ae7b2ab4f2f87989ff75dcc2f52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}